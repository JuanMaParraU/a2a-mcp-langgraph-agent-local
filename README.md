# A2A MCP LangGraph Agent Local

> A fully local, open-source agentic AI system combining **LangGraph** for agent development, **Ollama** for LLM serving, Model Context Protocol (**MCP**), and Agent-to-Agent (**A2A**) communication â€” no subscriptions, no cloud APIs, complete control.

## ğŸ¯ What This Does

This project demonstrates a complete agentic AI stack running entirely on your machine:

- **ğŸ§­ LangGraph** orchestrates multi-agent workflows
- **ğŸ”Œ MCP** provides standardized tool access
- **ğŸ’¬ A2A** enables agent-to-agent communication
- **âš™ï¸ Ollama** serves local LLMs for reasoning

**Use cases:** Build research assistants, automated workflows, multi-agent systems, or experiment with agentic patterns â€” all without external API costs and full control.

**ğŸ“– Want to understand the architecture and concepts?** Read the [full blog post](https://your-blog-link.com)

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.10+**
- **8GB+ RAM** (16GB recommended for larger models)
- **tmux** (for running multiple services)
- **macOS, Linux, or Windows with WSL**

Whilst, the code can entirely run in CPU, it is recommended some sort of GPU accelarator for better experience (reduce latency). This implementation has been tested with commercial-grade solutions; M1, M3, RTX. 
### Step 1: Install Dependencies

**Install tmux:**

macOS:
```bash
brew install tmux
```

Ubuntu/Debian:
```bash
sudo apt-get install tmux
```

**Install Ollama:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

**Start Ollama and download model:**
```bash
ollama serve
ollama pull mistral-nemo # you can chose any open model available in Ollama. 
#if you change the model, make sure to update it accordingly in line 39 on src/a2a_3_agent.py
```

### Step 2: Clone and Setup

```bash
git clone https://github.com/JuanMaParraU/a2a-mcp-langgraph-agent-local.git
cd a2a-mcp-langgraph-agent-local
```

**Setup Python environment:**

Using `uv` (recommended):
```bash
uv sync
source .venv/bin/activate
```

Using standard venv:
```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### Step 3: Launch the System

```bash
chmod +x start_agents.sh
./start_agents.sh
```

This launches three services in separate tmux windows:
- **Window 0 (MCP):** MCP Server providing tools
- **Window 1 (Agent):** Agent Server with A2A + LangGraph
- **Window 2 (Client):** Interactive client for sending tasks

You should see something like this:


![Demo welcome screen](figures/start_agent.png)

---

## ğŸ® Managing the Tmux Session
If you are not familiar with tmux sessions, please visist [.......] for a quick introduction. 

### Switching Between Windows

```
Ctrl+b then 0  â†’  MCP Server
Ctrl+b then 1  â†’  Agent Server
Ctrl+b then 2  â†’  Client
```

Or cycle through:
```
Ctrl+b then n  â†’  Next window
Ctrl+b then p  â†’  Previous window
```

### Detach and Reattach

**Detach** (leave running in background):
```
Ctrl+b then d
```

**Reattach:**
```bash
tmux attach -t agentic-ai
```

### Stop the System
From any of the windows, press ```Ctrl + c``` and then

```bash
tmux kill-server
```
or 

```bash
tmux kill-session -t agentic-ai
```
---

## ğŸ—ï¸ Architecture Overview

```mermaid
graph TB
    User[ğŸ‘¤ User]
    Client[client.py<br/>A2A Client]
     subgraph A2A_Stack["ğŸŒ A2A Agent Stack"]
        Starlette[a2a_1_starlette.py<br/>HTTP Server Starlette<br/>â€¢ REST API endpoints<br/>â€¢ A2A protocol]
        Executor[a2a_2_executor.py<br/>Task Execution Engine<br/>â€¢ Task lifecycle<br/>â€¢ Error handling]
        Agent[a2a_3_agent.py<br/>LangGraph Agent Core<br/>â€¢ Agent reasoning<br/>â€¢ Ollama LLM backend<br/>â€¢ MCP client]
    end
     subgraph MCP_Stack["ğŸ”Œ MCP Tool Stack"]
        MCP[mcp_server.py<br/>MCP Protocol Layer<br/>â€¢ Standardizes tool access<br/>â€¢ Formats responses<br/>â€¢ Tool discovery]
         subgraph Tools["âš™ï¸ Actual Tools"]
            DDG[ğŸ” DuckDuckGo<br/>Search]
            ArXiv[ğŸ“š arXiv<br/>Search]
            Wiki[ğŸ“– Wikipedia<br/>Search]
        end
    end
     Ollama[(ğŸ¦™ Ollama<br/>Local LLM)]
     User -->|HTTP Request| Client
     Client -->|POST /send_message| Starlette
     Starlette -->|wraps| Executor
     Executor -->|wraps| Agent
     Agent -->|connects to| MCP
     Agent -.->|reasoning| Ollama
     MCP -->|wraps| Tools
     MCP -->|executes| DDG
     MCP -->|executes| ArXiv
     MCP -->|executes| Wiki
```

**Read more:** [Blog post with detailed architecture explanation](https://your-blog-link.com)

---

## ğŸ“ Deep Dive

For detailed file descriptions, customization options, and examples, see the [src/ folder documentation](src/README.md).

---

## ğŸ› Troubleshooting

### Ollama Connection Issues

**Error:** `ConnectionRefusedError: [Errno 61] Connection refused`

**Solution:** Make sure Ollama is running:
```bash
ollama serve
```

### Model Not Found

**Error:** `Model 'mistral-nemo' not found`

**Solution:**
```bash
ollama pull mistral-nemo
```

### Import Errors

**Solution:** Ensure virtual environment is activated (uv or venv):
```bash
source .venv/bin/activate
pip install -r requirements.txt
```

### tmux Session Already Exists

**Solution:**
```bash
tmux kill-session -t agentic-ai
./start_agents_tmux.sh
```

---

## ğŸ¤ Contributing

Contributions welcome! Areas of interest:

- ğŸ”­ **Observability tools** â€” visualize agent graphs and state
- ğŸ§© **Advanced A2A patterns** â€” negotiation, consensus protocols
- âš™ï¸ **New MCP tools** â€” database access, API integrations
- ğŸ§  **Model benchmarks** â€” performance comparisons
- ğŸ“š **Documentation** â€” tutorials, examples, explanations

**How to contribute:**
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a Pull Request

**Questions or ideas?** [Open an issue](https://github.com/JuanMaParraU/a2a-mcp-langgraph-agent-local/issues)

---

## ğŸ“– Learn More

- **Blog Post:** [Building Fully Local Agentic AI](https://your-blog-link.com)
- **Source Code Details:** [src/ folder documentation](src/README.md)
- **LangGraph Docs:** [langchain-ai.github.io/langgraph](https://langchain-ai.github.io/langgraph/)
- **MCP Specification:** [Anthropic Model Context Protocol](https://www.anthropic.com/news/model-context-protocol)
- **A2A Specification:** [insert link]()
- **Ollama:** [ollama.ai](https://ollama.ai)

---
## TODO 
- Define the model remotly: Make the model a variable that can be updated. Allow the user define the model to talk to.
- Dynamic Agent Skills Retrieval and Definition: This task aims to enable agents to dynamically access and define their skills through MCP queries, allowing for greater flexibility and adaptability in handling various tasks. (Issue)
- Multi-agent Workflows: Implement a system that enables multiple agents to collaborate and execute complex tasks by defining and managing interactions between them. This will allow for the creation of more sophisticated AI solutions that leverage the unique capabilities of each agent. (Issue)
- Multi-step Workflows: Develop a mechanism for agents to execute multi-step workflows by breaking down complex tasks into smaller, manageable subtasks and orchestrating their execution in the appropriate sequence. This will improve the efficiency and effectiveness of AI systems in handling intricate problems. (Issue)
- Local Tooling Definitions: Create a repository of local tools that can be easily integrated into agent workflows, further expanding their capabilities without relying on external APIs or services. This will enhance the autonomy and control offered by our AI system. (Issue)

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details

---

**Questions? Feedback?** Open an issue or reach out â€” I'd love to hear what you're building with this!

*Part of our exploration into accessible, open-source agentic AI infrastructure.*
